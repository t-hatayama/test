{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "    \n",
    "train_loss_list=[]\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) #高速版！\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  acc, test acc | 0.112366666667, 0.1135\n",
      "train  acc, test acc | 0.793716666667, 0.7986\n",
      "train  acc, test acc | 0.877216666667, 0.8814\n",
      "train  acc, test acc | 0.899066666667, 0.903\n",
      "train  acc, test acc | 0.9083, 0.9121\n",
      "train  acc, test acc | 0.915633333333, 0.9175\n",
      "train  acc, test acc | 0.918783333333, 0.9208\n",
      "train  acc, test acc | 0.924283333333, 0.9276\n",
      "train  acc, test acc | 0.927766666667, 0.9298\n",
      "train  acc, test acc | 0.931416666667, 0.9358\n",
      "train  acc, test acc | 0.934333333333, 0.9352\n",
      "train  acc, test acc | 0.93695, 0.9381\n",
      "train  acc, test acc | 0.9393, 0.9401\n",
      "train  acc, test acc | 0.9417, 0.9421\n",
      "train  acc, test acc | 0.943533333333, 0.9435\n",
      "train  acc, test acc | 0.945016666667, 0.9438\n",
      "train  acc, test acc | 0.947083333333, 0.9466\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "    \n",
    "train_loss_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "#1エポックあたりの繰り返し数\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "#     grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch) #高速版！\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    #1エポックごと認識精度を計算\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train  acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40163, 18557, 30012, 15089,   481, 41445, 45811, 13916, 20237,\n",
       "       36029, 21223, 13329, 35144, 23297,  6739, 35890, 18558, 32020,\n",
       "       27204,  6863, 22159, 43617, 18300, 18265, 53257, 37857, 14719,\n",
       "       33173, 16657, 55707, 45049, 50874, 57691, 39030, 18795, 48409,\n",
       "       29884,  9089, 56884, 20438, 42654, 44800, 49138, 20416, 22078,\n",
       "       34726,  5807, 55912, 11406, 37525, 52615, 33326, 25747, 20328,\n",
       "       58411, 32218, 56475, 43493, 25292, 15780,  9120, 47521, 50860,\n",
       "       36600, 16176, 19902, 36868, 40033, 19715, 51308, 34248, 42684,\n",
       "       25345, 14873, 19059, 35592, 51054, 50150, 31524, 12429, 50944,\n",
       "       54071, 59303, 47005, 29571,  4790, 59262, 49037,  2725, 23590,\n",
       "       15819, 18101, 29151, 39718, 17312, 12732, 42570, 49174, 35651, 45560])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
